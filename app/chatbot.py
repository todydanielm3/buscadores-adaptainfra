import os, base64, re
from pathlib import Path
import streamlit as st
from dotenv import load_dotenv

# ImportaÃ§Ãµes condicionais para o Gemini
try:
    from langchain_google_genai import ChatGoogleGenerativeAI
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("Gemini nÃ£o disponÃ­vel - modo simplificado ativado")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Chave da API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
except Exception:
    API_KEY = os.getenv("GOOGLE_API_KEY")

if not API_KEY:
    st.error("Chave da API do Gemini nÃ£o encontrada.")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Imagem do chatbot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ASSETS_DIR = Path(__file__).parent.parent / "assets"
IMG_PATH = ASSETS_DIR / "VerichIA.png"

def _img_b64(file_path: Path | str) -> str:
    with open(file_path, "rb") as img:
        return base64.b64encode(img.read()).decode()

def _detectar_idioma(txt: str) -> str:
    pt_kw = ["nÃ£o","informaÃ§Ã£o","por favor","obrigado","vocÃª","como","qual","quem","onde","quando",
             "por quÃª","porque","responda","me fale","me diga"]
    es_kw = ["no","informaciÃ³n","por favor","gracias","usted","cÃ³mo","cuÃ¡l","quiÃ©n","dÃ³nde","cuÃ¡ndo",
             "por quÃ©","porque","responde","dime","cuÃ©ntame"]
    pt = sum(1 for p in pt_kw if re.search(rf"\b{p}\b", txt.lower()))
    es = sum(1 for p in es_kw if re.search(rf"\b{p}\b", txt.lower()))
    return "es" if es > pt else "pt"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FunÃ§Ã£o principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def show_chatbot() -> None:
    # Verificar se hÃ¡ pergunta na URL
    question_from_url = st.query_params.get("question", "")
    
    mini_logo_b64 = _img_b64(IMG_PATH)

    # Interface visual do chatbot
    st.markdown(
        f"""
        <div style="text-align: center; margin-bottom: 30px;">
            <img src="data:image/png;base64,{mini_logo_b64}" width="80">
            <h1 style="font-family: 'Roboto', sans-serif; color: #333;">OLABOT</h1>
            <p style="font-family: 'Roboto', sans-serif;">Assistente Inteligente OLACEFS</p>
        </div>
        
        <style>
        .chat-message {{
            display: flex;
            align-items: flex-start;
            margin: 1rem 0;
            padding: 1rem;
            border-radius: 10px;
            background-color: #f8f9fa;
        }}
        .chat-user {{
            background-color: #007bff;
            color: white;
            margin-left: auto;
            max-width: 70%;
            justify-content: flex-end;
        }}
        .chatbot-avatar {{
            width: 40px;
            height: 40px;
            border-radius: 50%;
            margin-right: 10px;
        }}
        .chatbot-text {{
            flex: 1;
        }}
        </style>
        """,
        unsafe_allow_html=True
    )

    # â”€â”€â”€â”€â”€ Session state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # â”€â”€â”€â”€â”€ LLM simplificado (sem RAG) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "gemini_llm" not in st.session_state and API_KEY and GEMINI_AVAILABLE:
        try:
            st.session_state.gemini_llm = ChatGoogleGenerativeAI(
                model="gemini-1.5-flash",
                google_api_key=API_KEY,
                temperature=0.7,
                transport="rest",
            )
        except Exception as e:
            st.session_state.gemini_llm = None
            print(f"Erro ao inicializar Gemini: {e}")
    elif not API_KEY or not GEMINI_AVAILABLE:
        st.session_state.gemini_llm = None

    # â”€â”€â”€â”€â”€ Render histÃ³rico â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for m in st.session_state.chat_history:
        if m["role"] == "user":
            st.markdown(f"<div class='chat-message chat-user'>{m['content']}</div>",
                        unsafe_allow_html=True)
        else:
            st.markdown(
                f"""<div class='chat-message'>
                       <img src="data:image/png;base64,{mini_logo_b64}" class='chatbot-avatar'>
                       <div class='chatbot-text'>{m['content']}</div></div>""",
                unsafe_allow_html=True,
            )

    # â”€â”€â”€â”€â”€ Entrada do usuÃ¡rio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Se hÃ¡ pergunta da URL, processar automaticamente
    if question_from_url and not st.session_state.get("url_question_processed", False):
        prompt = question_from_url
        st.session_state.url_question_processed = True
        # Limpar o parÃ¢metro da URL para evitar repetiÃ§Ã£o  
        st.query_params.pop("question", None)
        
        # Mostrar a pergunta do usuÃ¡rio
        st.markdown(f"<div class='chat-message chat-user'>{prompt}</div>",
                    unsafe_allow_html=True)
        
        # Processar automaticamente
        auto_process = True
    else:
        prompt = st.chat_input("Mensagem ao Chatbot:")
        auto_process = False
    
    # â”€â”€â”€â”€â”€ BotÃ£o Voltar logo abaixo da barra de entrada â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if not prompt and not auto_process:
        st.markdown("<br>", unsafe_allow_html=True)
        if st.button("ğŸ  Voltar ao Menu"):
            st.session_state.page = "menu"
            st.query_params.update({"page": "menu"})
            st.rerun()
        return

    # â”€â”€â”€â”€â”€ RodapÃ© no final da pÃ¡gina â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown(
        """
        """,
        unsafe_allow_html=True
    )
    
    if not prompt and not auto_process:
        return

    # Processar mensagem (tanto manual quanto automÃ¡tica)
    if prompt:
        st.session_state.chat_history.append({"role": "user", "content": prompt})

        with st.spinner("Analisando..."):
            try:
                if st.session_state.gemini_llm:
                    # Detectar idioma e configurar resposta
                    idioma = _detectar_idioma(prompt)
                    sys_prompt = ("Eres OLABOT, un asistente de OLACEFS especializado en auditorÃ­a, "
                                 "infraestrutura sustentÃ¡vel e transparÃªncia. Responde siempre en espaÃ±ol, "
                                 "de forma clara, Ãºtil e profissional."
                                 if idioma == "es"
                                 else "VocÃª Ã© OLABOT, um assistente da OLACEFS especializado em auditoria, "
                                 "infraestrutura sustentÃ¡vel e transparÃªncia. Responda sempre em portuguÃªs, "
                                 "de forma clara, Ãºtil e profissional.")
                    
                    # Contexto especÃ­fico para OLASIS
                    context = f"{sys_prompt}\n\nContexto: OLASIS Ã© o Sistema de InformaciÃ³n Sostenible da OLACEFS."
                    full_prompt = f"{context}\n\nPergunta: {prompt}"
                    
                    resp = st.session_state.gemini_llm.invoke(full_prompt)
                    resposta = getattr(resp, "content", str(resp))
                else:
                    # Resposta padrÃ£o sem API
                    resposta = ("Â¡Hola! Soy OLABOT de OLACEFS. Actualmente estoy en modo simplificado. "
                               "Â¿En quÃ© puedo ayudarte com informaÃ§Ãµes sobre auditoria e infraestrutura sustentÃ¡vel?"
                               if _detectar_idioma(prompt) == "es"
                               else "OlÃ¡! Sou OLABOT da OLACEFS. Atualmente estou em modo simplificado. "
                               "Como posso ajudar com informaÃ§Ãµes sobre auditoria e infraestrutura sustentÃ¡vel?")
            except Exception as exc:
                resposta = (f"Disculpa, ocurriÃ³ un error inesperado. Por favor, intenta de nuevo."
                           if _detectar_idioma(prompt) == "es"
                           else f"Desculpe, ocorreu um erro inesperado. Por favor, tente novamente.")

        st.session_state.chat_history.append({"role": "model", "content": resposta})
        st.rerun()
